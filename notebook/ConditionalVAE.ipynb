{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConditionalVAE.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGlXDLg9J4AO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.datasets import fetch_olivetti_faces"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQRkA63u_45B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a9ae676b-223c-4949-ac1a-d30f51f14afd"
      },
      "source": [
        "(x_train,y_train) , (x_test,y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train=x_train.reshape(60000,28,28,1).astype('float32')/255.0\n",
        "x_test=x_test.reshape(10000,28,28,1).astype('float32')/255.0\n",
        "x_train[x_train>=.5]=1.\n",
        "x_train[x_train<.5]=0.\n",
        "x_test[x_test>=.5]=1.\n",
        "x_test[x_test<.5]=0."
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYOj7mK2ySJv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs=10\n",
        "batch_size=16\n",
        "dataset=tf.data.Dataset.from_tensor_slices((x_train,x_train)).batch(16).repeat()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJ3BmIx6tuyG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "h_img,w_img=224,224"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4YC-u3vsejV",
        "colab_type": "code",
        "outputId": "2c945235-278f-492d-fca5-e7b3ee5b49c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "source": [
        "def conv_layer(layer,filters,\n",
        "               kernel,activation='relu',\n",
        "               padding='same',strides=1):\n",
        "  layer=tf.keras.layers.Conv2D(filters=filters,\n",
        "                         kernel_size=kernel,\n",
        "                         strides=strides,\n",
        "                         activation=activation,\n",
        "                         padding=padding)(layer)\n",
        "  return layer\n",
        "  \n",
        "def conv_transpose_layer(layer,filters,\n",
        "               kernel,activation='relu',\n",
        "               padding='same',strides=1):\n",
        "  layer=tf.keras.layers.Conv2DTranspose(filters=filters,\n",
        "                         kernel_size=kernel,\n",
        "                         strides=strides,\n",
        "                         activation=activation,\n",
        "                         padding=padding)(layer)\n",
        "  return layer\n",
        "\n",
        "\n",
        "def model(input_shape,latent_dim):\n",
        "  #Encoder \n",
        "  model_input=tf.keras.Input(input_shape)\n",
        "  layer=conv_layer(model_input,32,3)\n",
        "  layer=conv_layer(layer,16,3,strides=2)\n",
        "  layer=conv_layer(layer,32,3,strides=2)\n",
        "  shape_before_flatten=layer.shape\n",
        "  layer=tf.keras.layers.Flatten()(layer)\n",
        "  mean=tf.keras.layers.Dense(latent_dim)(layer)\n",
        "  var=tf.keras.layers.Dense(latent_dim)(layer)\n",
        "  encoder_model=tf.keras.models.Model(model_input,[mean,var])\n",
        "  \n",
        "  #Decoder\n",
        "  decoder_input=tf.keras.Input((latent_dim,))\n",
        "  layer=tf.keras.layers.Dense(np.prod(shape_before_flatten[1:]),\\\n",
        "                              activation='relu')(decoder_input)\n",
        "  layer=tf.keras.layers.Reshape(target_shape=shape_before_flatten[1:])(layer)\n",
        "  layer=conv_transpose_layer(layer,32,3,strides=2)\n",
        "  layer=conv_transpose_layer(layer,16,3,strides=2)\n",
        "  layer=conv_transpose_layer(layer,1,3,activation='sigmoid')\n",
        "  decoder_model=tf.keras.models.Model(decoder_input,layer)  \n",
        " \n",
        "  #Reparameterization Trick\n",
        "  mean,var=encoder_model(model_input)\n",
        "  epsilon=tf.random.normal(shape=(tf.shape(var)[0],\n",
        "                                  tf.shape(var)[1]))\n",
        "  z=mean+tf.exp(var)*epsilon\n",
        "  model_out=decoder_model(z)\n",
        "  model=tf.keras.models.Model(model_input,model_out)\n",
        "  model.summary()\n",
        "\n",
        "  #KL div loss\n",
        "  kl_loss= 0.5 * tf.reduce_mean(tf.square(mean) - 1 - var + tf.exp(var))\n",
        "  #Reconstruction loss\n",
        "  reconstruction_loss = tf.keras.losses.binary_crossentropy(tf.keras.backend.flatten(model_input),\n",
        "                                            tf.keras.backend.flatten(model_out))\n",
        "  vae_loss = tf.keras.backend.mean(reconstruction_loss + kl_loss)\n",
        "  model.add_loss(vae_loss)\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(0.01))\n",
        "  return model,decoder_model\n",
        "\n",
        "input_shape=(28,28,1)\n",
        "latent_dim=2\n",
        "vae_model,decoder_model=model(input_shape,latent_dim)\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "model_6 (Model)                 [(None, 2), (None, 2 15860       input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Shape_6 (TensorFlow [(2,)]               0           model_6[1][1]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Shape_7 (TensorFlow [(2,)]               0           model_6[1][1]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_4 (Te [()]                 0           tf_op_layer_Shape_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_5 (Te [()]                 0           tf_op_layer_Shape_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_shape_8 (TensorFlow [(2,)]               0           tf_op_layer_strided_slice_4[0][0]\n",
            "                                                                 tf_op_layer_strided_slice_5[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_RandomStandardNorma [(None, None)]       0           tf_op_layer_shape_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Mul_10 (TensorFlowO [(None, None)]       0           tf_op_layer_RandomStandardNormal_\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Exp_4 (TensorFlowOp [(None, 2)]          0           model_6[1][1]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Add_2 (TensorFlowOp [(None, None)]       0           tf_op_layer_Mul_10[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Mul_11 (TensorFlowO [(None, 2)]          0           tf_op_layer_Exp_4[0][0]          \n",
            "                                                                 tf_op_layer_Add_2[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_AddV2_12 (TensorFlo [(None, 2)]          0           model_6[1][0]                    \n",
            "                                                                 tf_op_layer_Mul_11[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "model_7 (Model)                 (None, 28, 28, 1)    18721       tf_op_layer_AddV2_12[0][0]       \n",
            "==================================================================================================\n",
            "Total params: 34,581\n",
            "Trainable params: 34,581\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tzl6_MTG0xq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "02842e46-6bc6-4764-bf41-6e5b9b86abe4"
      },
      "source": [
        "callback=[(tf.keras.callbacks.ModelCheckpoint(filepath='/content/mnist_model.h5',\n",
        "                                            patience=0, verbose=0))]\n",
        "vae_model.fit(dataset,epochs=epochs,callbacks=callback,steps_per_epoch=(len(x_train)//batch_size))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "3750/3750 [==============================] - 153s 41ms/step - loss: 0.2654\n",
            "Epoch 2/10\n",
            "3750/3750 [==============================] - 147s 39ms/step - loss: 0.2639\n",
            "Epoch 3/10\n",
            "3750/3750 [==============================] - 151s 40ms/step - loss: 0.2640\n",
            "Epoch 4/10\n",
            "1076/3750 [=======>......................] - ETA: 1:45 - loss: 0.2645"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSyfWEjbZKk_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "bb0198bf-2be9-4c59-c46a-2f070f03ec3a"
      },
      "source": [
        "#Testing\n",
        "num_example=1\n",
        "test_example=tf.random.normal(shape=[num_example,latent_dim])\n",
        "pred=decoder_model.predict(test_example)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(np.reshape(pred,(28,28)))\n",
        "plt.show()\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTMs6ApZJ8Nb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zy5q1Jw68kQR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        },
        "outputId": "53098899-9562-4f24-fecb-ce277a7f9e7c"
      },
      "source": [
        "pred=vae_model.predict(x_test[0])\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(np.reshape(pred,(28,28)))\n",
        "plt.show()\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28, 1) for input Tensor(\"input_3:0\", shape=(None, 28, 28, 1), dtype=float32), but it was called on an input with incompatible shape (None, 28, 1, 1).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28, 1) for input Tensor(\"input_3:0\", shape=(None, 28, 28, 1), dtype=float32), but it was called on an input with incompatible shape (None, 28, 1, 1).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-8d961f72865f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvae_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m     87\u001b[0m           method.__name__))\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m   return tf_decorator.make_decorator(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1266\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1267\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1268\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1269\u001b[0m             \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1270\u001b[0m             \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    616\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2417\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2419\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2420\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2772\u001b[0m           \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2773\u001b[0m           and call_context_key in self._function_cache.missed):\n\u001b[0;32m-> 2774\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_define_function_with_shape_relaxation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2704\u001b[0m         relaxed_arg_shapes)\n\u001b[1;32m   2705\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-> 2706\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   2707\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1147 predict_function  *\n        outputs = self.distribute_strategy.run(\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1122 predict_step  **\n        return self(x, training=False)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:927 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py:719 call\n        convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py:888 _run_internal_graph\n        output_tensors = layer(computed_tensors, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:927 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py:719 call\n        convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/network.py:888 _run_internal_graph\n        output_tensors = layer(computed_tensors, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:886 __call__\n        self.name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py:216 assert_input_compatibility\n        ' but received input with shape ' + str(shape))\n\n    ValueError: Input 0 of layer dense_4 is incompatible with the layer: expected axis -1 of input shape to have value 1568 but received input with shape [None, 224]\n"
          ]
        }
      ]
    }
  ]
}